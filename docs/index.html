<html>
<head>
  <script src="https://api.html5media.info/1.1.8/html5media.min.js"></script>
</head>
<body>
  <h1>Draft Punk</h1>
  <p>David Goedicke &amp; J.D. Zamfirescu-Pereira</p>
  <p>Inspired by recent work in algorithmic visual style transfer, we set out to build a system that uses reinforcement learning techniques to provide artists with a novel interface for creating music in the style of previous work, reproducing a previous artist’s “signature” or “essential” sound. Our intent was to build a system based on promising deep learning approaches to pattern matching for deeply complex but hierarchical data, using such to identify, for a given artist, the major audio frequency components associated with a particular note (and in relation to previous notes), creating an “audiography” for that artist. Users would then be able to select an artist and create new music in the style of that artist.</p>
  <p>While we believe that such a project is possible, and our approach is plausible, the complexity of what we set out to do vastly exceeded the time and computational power we had at our disposal. Nevertheless, our experimentation in this direction yielded a few interesting insights and sounds, which we have loosely organized here.</p>

  
  <!-- <p>Hey, listen to this: <audio src="https://media.githubusercontent.com/media/dgjz-music-composition-services/NeuralNetSynth/master/4Beats2.wav" controls preload></audio></p> -->
</body>
</html>
